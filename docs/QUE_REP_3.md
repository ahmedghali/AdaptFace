# Questions & RÃ©ponses - Partie 3 (Questions AvancÃ©es)

> Explications approfondies sur les Transformers, l'entraÃ®nement, et HuggingFace.

---

## 1. Google Colab vs Mon PC - Gain de temps?

### Comparaison des GPUs

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    COMPARAISON GPU                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  TON PC (RTX 3060/4070):                                       â”‚
â”‚  â”œâ”€ VRAM: 8-12 GB                                              â”‚
â”‚  â”œâ”€ Performance: ~15-20 TFLOPS                                 â”‚
â”‚  â””â”€ DisponibilitÃ©: 24/7, pas de limite                         â”‚
â”‚                                                                 â”‚
â”‚  GOOGLE COLAB (Gratuit):                                       â”‚
â”‚  â”œâ”€ GPU: T4 (16 GB VRAM)                                       â”‚
â”‚  â”œâ”€ Performance: ~8 TFLOPS (plus LENT que ton PC!)            â”‚
â”‚  â”œâ”€ Limite: ~12h puis dÃ©connexion                              â”‚
â”‚  â””â”€ File d'attente: peut Ãªtre indisponible                     â”‚
â”‚                                                                 â”‚
â”‚  GOOGLE COLAB PRO ($10/mois):                                  â”‚
â”‚  â”œâ”€ GPU: V100 ou A100 (16-40 GB VRAM)                         â”‚
â”‚  â”œâ”€ Performance: ~30-80 TFLOPS                                 â”‚
â”‚  â”œâ”€ Limite: ~24h                                               â”‚
â”‚  â””â”€ PrioritÃ© d'accÃ¨s                                           â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Estimation du temps

| Configuration | Temps estimÃ© (40 epochs) |
|---------------|--------------------------|
| Ton PC (RTX 3060) | ~36 heures |
| Colab Gratuit (T4) | ~45-50 heures (plus LENT + dÃ©connexions!) |
| Colab Pro (V100) | ~18-20 heures |
| Colab Pro (A100) | ~10-12 heures |

### Ma recommandation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RECOMMANDATION:                                                â”‚
â”‚                                                                 â”‚
â”‚  1. GARDE ton PC pour l'entraÃ®nement                           â”‚
â”‚     - Pas de dÃ©connexion                                        â”‚
â”‚     - Pas de limite de temps                                    â”‚
â”‚     - Tu peux dormir pendant que Ã§a tourne                     â”‚
â”‚                                                                 â”‚
â”‚  2. Utilise Colab SEULEMENT pour:                              â”‚
â”‚     - Tests rapides                                             â”‚
â”‚     - Debugging                                                 â”‚
â”‚     - Si tu veux tester A100 (Colab Pro)                       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. C'est quoi Self-Attention? (Explication simple)

### Le problÃ¨me que Self-Attention rÃ©sout

```
Imagine une phrase: "Le chat dort sur le canapÃ©"

Question: Comment le modÃ¨le sait que "dort" est liÃ© Ã  "chat"?

SANS attention: Chaque mot est traitÃ© indÃ©pendamment
  â†’ Le modÃ¨le ne comprend pas les relations

AVEC attention: Chaque mot "regarde" tous les autres mots
  â†’ Le modÃ¨le comprend que "dort" est l'action du "chat"
```

### Pour les images (notre cas)

```
Une image 224Ã—224 est dÃ©coupÃ©e en PATCHES (morceaux):

â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”
â”‚ 1 â”‚ 2 â”‚ 3 â”‚ 4 â”‚     16Ã—16 patches
â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤     = 256 patches pour 224Ã—224 (16Ã—16)
â”‚ 5 â”‚ 6 â”‚ 7 â”‚ 8 â”‚     (avec patch size 14)
â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
â”‚ 9 â”‚10 â”‚11 â”‚12 â”‚
â”œâ”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¼â”€â”€â”€â”¤
â”‚13 â”‚14 â”‚15 â”‚16 â”‚
â””â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”˜

Self-Attention permet Ã  CHAQUE patch de "regarder"
TOUS les autres patches pour comprendre l'image globale.
```

### Exemple concret pour un visage

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚   Patch "Å“il gauche" regarde:                                  â”‚
â”‚   â”œâ”€ Patch "Å“il droit" â†’ "Ah, il y a symÃ©trie!"               â”‚
â”‚   â”œâ”€ Patch "nez" â†’ "Je suis au-dessus du nez"                 â”‚
â”‚   â”œâ”€ Patch "sourcil" â†’ "Mon sourcil est juste au-dessus"      â”‚
â”‚   â””â”€ Patch "bouche" â†’ "La bouche est plus bas"                â”‚
â”‚                                                                 â”‚
â”‚   RÃ©sultat: Le patch "Å“il gauche" comprend sa POSITION         â”‚
â”‚   et ses RELATIONS avec le reste du visage!                    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Visualisation du calcul

```
Self-Attention = "Qui doit regarder qui, et combien?"

EntrÃ©e: 256 patches, chaque patch = vecteur de 384 dims

Ã‰tape 1: Calculer les "scores d'attention"
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Patch 1 regarde Patch 1: score = 0.8   â”‚
â”‚  Patch 1 regarde Patch 2: score = 0.1   â”‚
â”‚  Patch 1 regarde Patch 3: score = 0.05  â”‚
â”‚  ...                                     â”‚
â”‚  (score Ã©levÃ© = "je dois faire attention â”‚
â”‚   Ã  ce patch!")                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ã‰tape 2: Combiner selon les scores
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Nouvelle reprÃ©sentation du Patch 1 =   â”‚
â”‚    0.8 Ã— Patch1 + 0.1 Ã— Patch2 + ...   â”‚
â”‚                                         â”‚
â”‚  = MÃ©lange intelligent de tous les     â”‚
â”‚    patches, pondÃ©rÃ© par l'importance   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. C'est quoi MLP (Feed-Forward)?

### Comparaison simple

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  SELF-ATTENTION = Communication ENTRE patches                   â”‚
â”‚  "Les patches se parlent entre eux"                            â”‚
â”‚                                                                 â”‚
â”‚  MLP = Traitement INDIVIDUEL de chaque patch                   â”‚
â”‚  "Chaque patch rÃ©flÃ©chit seul"                                 â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Structure du MLP

```
MLP = 2 couches linÃ©aires avec une activation

EntrÃ©e [384] â†’ Linear1 [384â†’1536] â†’ GELU â†’ Linear2 [1536â†’384] â†’ Sortie [384]
                     â†‘                              â†‘
                 Expansion (Ã—4)                 RÃ©duction
                "RÃ©flÃ©chir plus"            "RÃ©sumer"
```

### Analogie

```
Self-Attention = RÃ©union de groupe
  "Tout le monde partage ses idÃ©es"

MLP = Travail individuel
  "Chacun digÃ¨re les informations reÃ§ues"

Les deux sont nÃ©cessaires!
```

### Pourquoi on met LoRA sur l'Attention et pas le MLP?

```
Raison: L'attention capture les RELATIONS (plus important!)

Attention: "Quel patch regarde quel autre patch"
  â†’ C'est lÃ  que le modÃ¨le apprend les PATTERNS
  â†’ Modifier Ã§a change beaucoup le comportement

MLP: "Traitement gÃ©nÃ©rique des features"
  â†’ Moins spÃ©cifique Ã  la tÃ¢che
  â†’ Moins besoin de le modifier

MAIS on PEUT aussi mettre LoRA sur MLP si on veut!
C'est un choix de design. Nous on a choisi qkv + proj.
```

---

## 4. C'est quoi Projection Layer (PROJ)?

### Contexte

```
Dans Self-Attention, on a plusieurs "tÃªtes" (heads):

Multi-Head Attention:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  Head 1: Regarde les relations de forme                        â”‚
â”‚  Head 2: Regarde les relations de texture                      â”‚
â”‚  Head 3: Regarde les relations de position                     â”‚
â”‚  Head 4: Regarde les relations de couleur                      â”‚
â”‚  Head 5: ...                                                    â”‚
â”‚  Head 6: ...                                                    â”‚
â”‚                                                                 â”‚
â”‚  6 tÃªtes qui regardent des choses DIFFÃ‰RENTES!                 â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Le problÃ¨me

```
AprÃ¨s Multi-Head Attention, on a 6 rÃ©sultats diffÃ©rents.
Comment les COMBINER en un seul rÃ©sultat cohÃ©rent?

Head 1 output: [64 dims]
Head 2 output: [64 dims]    â†’  ConcatÃ©ner â†’ [384 dims]
Head 3 output: [64 dims]          â†“
Head 4 output: [64 dims]         PROJ
Head 5 output: [64 dims]          â†“
Head 6 output: [64 dims]    â†’  Sortie [384 dims]
```

### RÃ´le de PROJ

```
PROJ = Linear(384, 384)

Fonction:
1. MÃ‰LANGER les informations des diffÃ©rentes tÃªtes
2. APPRENDRE quelle combinaison est la meilleure
3. Produire une sortie COHÃ‰RENTE

Sans PROJ: Les tÃªtes ne communiquent pas entre elles
Avec PROJ: Le modÃ¨le apprend Ã  combiner intelligemment
```

---

## 5. Explication de "Sortie = WÃ—entrÃ©e + Î”"

### L'Ã©quation complÃ¨te

```
SANS LoRA:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  sortie = W Ã— entrÃ©e                    â”‚
â”‚                                         â”‚
â”‚  W = matrice de poids [384Ã—384]        â”‚
â”‚  entrÃ©e = vecteur [384]                â”‚
â”‚  sortie = vecteur [384]                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

AVEC LoRA:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  sortie = W Ã— entrÃ©e + Î”               â”‚
â”‚                                         â”‚
â”‚  OÃ¹ Î” = (B Ã— A) Ã— entrÃ©e               â”‚
â”‚                                         â”‚
â”‚  = W Ã— entrÃ©e + B Ã— A Ã— entrÃ©e         â”‚
â”‚  = (W + BÃ—A) Ã— entrÃ©e                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Visualisation

```
                    SANS LoRA

entrÃ©e [384] â”€â”€â†’ [ Ã— W ] â”€â”€â†’ sortie [384]


                    AVEC LoRA

                â”Œâ”€â”€â†’ [ Ã— W ] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
entrÃ©e [384] â”€â”€â”¤                           â”œâ”€â”€â†’ [+] â”€â”€â†’ sortie [384]
                â””â”€â”€â†’ [ Ã— A ] â”€â”€â†’ [ Ã— B ] â”€â”€â”˜
                         â†“           â†“
                      [16 dims]   [384 dims]

                    Î” = B Ã— A Ã— entrÃ©e
```

### Exemple numÃ©rique simplifiÃ©

```
entrÃ©e = [1, 2, 3]  (simplifiÃ© Ã  3 dims)

W = poids originaux (gelÃ©s)
A = LoRA down (compression)
B = LoRA up (expansion)

Calcul:
1. W Ã— entrÃ©e = [10, 20, 30]           (sortie originale)
2. A Ã— entrÃ©e = [5]                     (compressÃ© Ã  1 dim)
3. B Ã— [5] = [1, 2, 1]                  (Î”, la modification)
4. sortie finale = [10+1, 20+2, 30+1] = [11, 22, 31]

LoRA ajoute une PETITE modification Î” Ã  la sortie originale!
```

---

## 6. Pourquoi LoRA sur Attention et pas MLP?

### RÃ©ponse courte

```
On PEUT mettre LoRA partout! C'est un CHOIX de design.

Notre choix: qkv + proj (dans l'attention)

Pourquoi?
1. L'attention est PLUS IMPORTANTE pour adapter le modÃ¨le
2. Moins de paramÃ¨tres = plus rapide
3. C'est ce qui marche bien dans la littÃ©rature
```

### Comparaison

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OÃ™ METTRE LoRA?                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Option 1: Seulement qkv + proj (notre choix)                  â”‚
â”‚  â”œâ”€ ParamÃ¨tres: ~442K                                          â”‚
â”‚  â”œâ”€ Rapide Ã  entraÃ®ner                                         â”‚
â”‚  â””â”€ Suffisant pour la plupart des tÃ¢ches                       â”‚
â”‚                                                                 â”‚
â”‚  Option 2: qkv + proj + MLP (fc1, fc2)                         â”‚
â”‚  â”œâ”€ ParamÃ¨tres: ~1.2M                                          â”‚
â”‚  â”œâ”€ Plus lent                                                   â”‚
â”‚  â””â”€ Potentiellement meilleur pour tÃ¢ches complexes             â”‚
â”‚                                                                 â”‚
â”‚  Option 3: Partout (toutes les couches)                        â”‚
â”‚  â”œâ”€ ParamÃ¨tres: ~2M+                                           â”‚
â”‚  â”œâ”€ TrÃ¨s lent                                                   â”‚
â”‚  â””â”€ Risque de sur-apprentissage                                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 7. Plus d'explications sur PROJ

### Analogie avec une Ã©quipe

```
Imagine une Ã©quipe de 6 experts qui analysent un visage:

Expert 1 (Head 1): "Je vois la forme du nez"
Expert 2 (Head 2): "Je vois la texture de la peau"
Expert 3 (Head 3): "Je vois la position des yeux"
Expert 4 (Head 4): "Je vois les ombres"
Expert 5 (Head 5): "Je vois les contours"
Expert 6 (Head 6): "Je vois la symÃ©trie"

PROJ = Le chef d'Ã©quipe qui COMBINE tous les avis:
"D'accord, en combinant tout Ã§a, voici la description finale du visage"

PROJ apprend COMMENT combiner ces informations de maniÃ¨re optimale.
```

---

## 8. C'est quoi Q, K, V? Comment Ã§a marche?

### L'intuition

```
Q = Query (Question)     "Qu'est-ce que je cherche?"
K = Key (ClÃ©)           "Qu'est-ce que j'ai Ã  offrir?"
V = Value (Valeur)      "Quelle information je donne?"

Analogie: Recherche dans une bibliothÃ¨que

Query (Q):  "Je cherche des livres sur les chats"
Key (K):    Chaque livre a des mots-clÃ©s (titre, sujet)
Value (V):  Le contenu du livre

1. Comparer Q avec tous les K â†’ Scores de similaritÃ©
2. Les livres avec K similaires Ã  Q ont des scores Ã©levÃ©s
3. RÃ©cupÃ©rer les V des livres avec les meilleurs scores
```

### Pour les images

```
Chaque patch devient Q, K, et V:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Patch "Å“il gauche":                                           â”‚
â”‚                                                                 â”‚
â”‚  Q (Query): "Je suis un Å“il, qui d'autre est similaire?"       â”‚
â”‚  K (Key):   "Je suis un Å“il gauche Ã  cette position"           â”‚
â”‚  V (Value): "Voici mes caractÃ©ristiques: [0.2, 0.8, ...]"      â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Le calcul d'attention

```
EntrÃ©e X [256 patches Ã— 384 dims]
           â”‚
           â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚    QKV      â”‚  Une seule matrice qui produit Q, K, V
     â”‚ [384â†’1152]  â”‚  1152 = 384 Ã— 3 (pour Q, K, V)
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
     â”Œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”
     â–¼     â–¼     â–¼
    Q     K     V
 [384]  [384]  [384]
     â”‚     â”‚
     â–¼     â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Q Ã— K^T â”‚  Calculer les scores d'attention
   â”‚ /âˆš384   â”‚  (qui regarde qui?)
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Softmax â”‚  Normaliser les scores (somme = 1)
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
   Attention Ã— V  â†’  Sortie (mÃ©lange pondÃ©rÃ© des V)
```

### Exemple concret

```
Supposons 3 patches simplifiÃ©s:

Patch 1 (Å“il):     Q1, K1, V1
Patch 2 (nez):     Q2, K2, V2
Patch 3 (bouche):  Q3, K3, V3

Calcul pour Patch 1:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Score(1â†’1) = Q1 Â· K1 = 0.9  (trÃ¨s similaire Ã  lui-mÃªme)       â”‚
â”‚  Score(1â†’2) = Q1 Â· K2 = 0.3  (un peu liÃ© au nez)               â”‚
â”‚  Score(1â†’3) = Q1 Â· K3 = 0.1  (peu liÃ© Ã  la bouche)             â”‚
â”‚                                                                 â”‚
â”‚  AprÃ¨s Softmax: [0.7, 0.2, 0.1]                                â”‚
â”‚                                                                 â”‚
â”‚  Nouvelle reprÃ©sentation de Patch 1:                           â”‚
â”‚  = 0.7 Ã— V1 + 0.2 Ã— V2 + 0.1 Ã— V3                             â”‚
â”‚                                                                 â”‚
â”‚  = Patch 1 enrichi par les infos des autres patches!           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 9. Bases de donnÃ©es d'entraÃ®nement et de test

### Notre configuration

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ENTRAÃŽNEMENT                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Dataset: CASIA-WebFace                                         â”‚
â”‚  â”œâ”€ 494,149 images                                             â”‚
â”‚  â”œâ”€ 10,572 identitÃ©s (personnes diffÃ©rentes)                   â”‚
â”‚  â”œâ”€ ~47 images par personne en moyenne                         â”‚
â”‚  â””â”€ Chemin: data/casia-webface/                                â”‚
â”‚                                                                 â”‚
â”‚  Utilisation: Apprendre Ã  distinguer les visages               â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TEST (Benchmarks)                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. LFW (Labeled Faces in the Wild)                            â”‚
â”‚     â”œâ”€ 6,000 paires de visages                                 â”‚
â”‚     â”œâ”€ Type: GÃ©nÃ©ral                                            â”‚
â”‚     â””â”€ Question: "Ces 2 visages sont la mÃªme personne?"        â”‚
â”‚                                                                 â”‚
â”‚  2. CFP-FP (Celebrities Frontal-Profile)                       â”‚
â”‚     â”œâ”€ Visages frontaux vs profils                             â”‚
â”‚     â””â”€ Type: Variation de POSE                                 â”‚
â”‚                                                                 â”‚
â”‚  3. AgeDB-30 (Age Database)                                    â”‚
â”‚     â”œâ”€ MÃªme personne Ã  diffÃ©rents Ã¢ges                         â”‚
â”‚     â””â”€ Type: Variation d'Ã‚GE                                   â”‚
â”‚                                                                 â”‚
â”‚  4. CALFW (Cross-Age LFW)                                      â”‚
â”‚     â””â”€ Type: Ã‚GE                                               â”‚
â”‚                                                                 â”‚
â”‚  5. CPLFW (Cross-Pose LFW)                                     â”‚
â”‚     â””â”€ Type: POSE                                              â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Pourquoi des datasets diffÃ©rents?

```
ENTRAÃŽNEMENT â‰  TEST (trÃ¨s important!)

Si on teste sur les mÃªmes donnÃ©es qu'on entraÃ®ne:
  â†’ Le modÃ¨le peut "mÃ©moriser" au lieu d'apprendre
  â†’ Pas de garantie qu'il gÃ©nÃ©ralise

En utilisant des datasets DIFFÃ‰RENTS pour le test:
  â†’ On vÃ©rifie que le modÃ¨le a vraiment APPRIS
  â†’ Les personnes dans LFW ne sont PAS dans CASIA-WebFace
```

---

## 10. Puis-je publier mon modÃ¨le sur HuggingFace?

### OUI, absolument!

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PUBLICATION HUGGINGFACE                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Tu PEUX publier:                                               â”‚
â”‚  âœ“ Les poids LoRA/DA-LoRA (petits fichiers)                   â”‚
â”‚  âœ“ Le code du modÃ¨le                                           â”‚
â”‚  âœ“ Les rÃ©sultats et benchmarks                                 â”‚
â”‚  âœ“ Un demo/espace interactif                                   â”‚
â”‚                                                                 â”‚
â”‚  ATTENTION - Ne PAS publier:                                   â”‚
â”‚  âœ— Les poids complets de DINO/CLIP (appartiennent Ã  Meta/OpenAI)â”‚
â”‚  âœ— Le dataset CASIA-WebFace (licence restrictive)             â”‚
â”‚                                                                 â”‚
â”‚  MAIS - C'est OK car:                                          â”‚
â”‚  â†’ Les utilisateurs tÃ©lÃ©chargent DINO depuis Meta              â”‚
â”‚  â†’ Tu publies SEULEMENT tes poids LoRA (ce que tu as entraÃ®nÃ©) â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Comment publier

```python
# Installation
pip install huggingface_hub

# Connexion
huggingface-cli login

# CrÃ©er un repo et publier
from huggingface_hub import HfApi
api = HfApi()

# Upload ton modÃ¨le
api.upload_folder(
    folder_path="checkpoints/",
    repo_id="ton-username/AdaptFace-DALoRA",
    repo_type="model"
)
```

---

## 11. C'est quoi HuggingFace exactement?

### Description

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    HUGGINGFACE ðŸ¤—                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  C'est quoi?                                                    â”‚
â”‚  â†’ Le "GitHub" pour les modÃ¨les de Machine Learning            â”‚
â”‚  â†’ Plateforme de partage de modÃ¨les, datasets, et dÃ©mos        â”‚
â”‚                                                                 â”‚
â”‚  Services principaux:                                           â”‚
â”‚                                                                 â”‚
â”‚  1. HuggingFace Hub (hub.huggingface.co)                       â”‚
â”‚     â”œâ”€ TÃ©lÃ©charger des modÃ¨les prÃ©-entraÃ®nÃ©s                   â”‚
â”‚     â”œâ”€ Publier tes propres modÃ¨les                             â”‚
â”‚     â””â”€ Partager des datasets                                    â”‚
â”‚                                                                 â”‚
â”‚  2. Transformers (bibliothÃ¨que Python)                         â”‚
â”‚     â”œâ”€ Code pour utiliser les modÃ¨les                          â”‚
â”‚     â””â”€ pip install transformers                                â”‚
â”‚                                                                 â”‚
â”‚  3. Spaces (dÃ©mos interactives)                                â”‚
â”‚     â””â”€ CrÃ©er une interface web pour ton modÃ¨le                 â”‚
â”‚                                                                 â”‚
â”‚  4. Datasets (bibliothÃ¨que)                                    â”‚
â”‚     â””â”€ AccÃ©der facilement aux datasets publics                 â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Comment l'utiliser

```python
# Exemple: Charger un modÃ¨le depuis HuggingFace
from transformers import AutoModel

# TÃ©lÃ©charge automatiquement le modÃ¨le
model = AutoModel.from_pretrained("facebook/dinov2-small")

# Exemple: Publier ton modÃ¨le
model.push_to_hub("ton-username/mon-modele")
```

### FiabilitÃ©

```
HuggingFace est:
âœ“ UtilisÃ© par Google, Meta, Microsoft, OpenAI
âœ“ Standard de l'industrie pour le ML
âœ“ Open source et gratuit
âœ“ TrÃ¨s bien documentÃ©

Conseils:
1. Utilise les modÃ¨les "officiels" (vÃ©rifiÃ©s)
2. Lis les licences avant d'utiliser
3. VÃ©rifie les mÃ©triques et benchmarks publiÃ©s
```

---

## 12. Prompt pour visualiser les Transformers

### Prompt pour DALL-E / Midjourney / Stable Diffusion

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PROMPT RECOMMANDÃ‰                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  EN ANGLAIS (meilleurs rÃ©sultats):                             â”‚
â”‚                                                                 â”‚
â”‚  "Technical diagram of Vision Transformer (ViT) architecture,  â”‚
â”‚   showing image patches flowing through self-attention blocks, â”‚
â”‚   with Query, Key, Value vectors clearly labeled,              â”‚
â”‚   clean minimalist scientific illustration style,              â”‚
â”‚   white background, professional technical drawing,            â”‚
â”‚   educational diagram, neural network visualization"           â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Prompts spÃ©cifiques

```
Pour Self-Attention:
"Diagram showing self-attention mechanism,
 multiple patches connected with weighted arrows,
 attention scores visualized as connection strengths,
 clean technical illustration, white background"

Pour LoRA:
"Technical diagram of LoRA low-rank adaptation,
 showing frozen weights W plus small matrices A and B,
 matrix factorization visualization,
 clean minimalist scientific diagram"

Pour l'architecture complÃ¨te:
"Vision Transformer architecture diagram,
 input image split into patches,
 patches encoded and processed through transformer blocks,
 classification head at the end,
 technical blueprint style, labeled components"
```

### MEILLEURE OPTION: Utiliser des outils dÃ©diÃ©s

```
Pour des diagrammes VRAIMENT clairs, utilise plutÃ´t:

1. draw.io (gratuit)
   â†’ https://draw.io
   â†’ Tu dessines toi-mÃªme, contrÃ´le total

2. Excalidraw (gratuit)
   â†’ https://excalidraw.com
   â†’ Style "dessinÃ© Ã  la main", joli

3. TikZ/LaTeX (pour papers)
   â†’ Diagrammes vectoriels de qualitÃ© publication

4. Lucidchart
   â†’ Diagrammes professionnels

5. Mermaid (dans Markdown)
   â†’ Diagrammes en code texte
```

### Exemple de diagramme en texte (que tu peux copier)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VISION TRANSFORMER (ViT)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Image 224Ã—224                                                  â”‚
â”‚       â”‚                                                         â”‚
â”‚       â–¼                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚
â”‚  â”‚ Patch Embed â”‚  DÃ©couper en 256 patches de 14Ã—14             â”‚
â”‚  â”‚ + Position  â”‚  Ajouter info de position                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
â”‚       â”‚                                                         â”‚
â”‚       â–¼                                                         â”‚
â”‚  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—             â”‚
â”‚  â•‘           TRANSFORMER BLOCK (Ã—12)             â•‘             â”‚
â”‚  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£             â”‚
â”‚  â•‘                                               â•‘             â”‚
â”‚  â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘             â”‚
â”‚  â•‘  â”‚         SELF-ATTENTION                  â”‚ â•‘             â”‚
â”‚  â•‘  â”‚  â”Œâ”€â”€â”€â”€â”€â”                                â”‚ â•‘             â”‚
â”‚  â•‘  â”‚  â”‚ QKV â”‚ â†’ Q, K, V                      â”‚ â•‘             â”‚
â”‚  â•‘  â”‚  â””â”€â”€â”€â”€â”€â”˜                                â”‚ â•‘             â”‚
â”‚  â•‘  â”‚      â†“                                  â”‚ â•‘             â”‚
â”‚  â•‘  â”‚  Attention = softmax(QÂ·K^T/âˆšd) Ã— V     â”‚ â•‘             â”‚
â”‚  â•‘  â”‚      â†“                                  â”‚ â•‘             â”‚
â”‚  â•‘  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”                               â”‚ â•‘             â”‚
â”‚  â•‘  â”‚  â”‚ PROJ â”‚ â†’ Combiner les tÃªtes          â”‚ â•‘             â”‚
â”‚  â•‘  â”‚  â””â”€â”€â”€â”€â”€â”€â”˜                               â”‚ â•‘             â”‚
â”‚  â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘             â”‚
â”‚  â•‘                    â†“                         â•‘             â”‚
â”‚  â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘             â”‚
â”‚  â•‘  â”‚              MLP                        â”‚ â•‘             â”‚
â”‚  â•‘  â”‚  Linear â†’ GELU â†’ Linear                 â”‚ â•‘             â”‚
â”‚  â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘             â”‚
â”‚  â•‘                                               â•‘             â”‚
â”‚  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•             â”‚
â”‚       â”‚                                                         â”‚
â”‚       â–¼                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚
â”‚  â”‚   [CLS]     â”‚  Token de classification                      â”‚
â”‚  â”‚   Token     â”‚  â†’ ReprÃ©sentation globale de l'image          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
â”‚       â”‚                                                         â”‚
â”‚       â–¼                                                         â”‚
â”‚  Embedding [384 dims] â†’ Projection â†’ [512 dims]                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## RÃ©sumÃ© des Points ClÃ©s

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CE QU'IL FAUT RETENIR                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. Google Colab gratuit est PLUS LENT que ton PC!             â”‚
â”‚                                                                 â”‚
â”‚  2. Self-Attention = les patches se "regardent" entre eux      â”‚
â”‚                                                                 â”‚
â”‚  3. MLP = traitement individuel de chaque patch                â”‚
â”‚                                                                 â”‚
â”‚  4. PROJ = combiner les rÃ©sultats des diffÃ©rentes "tÃªtes"      â”‚
â”‚                                                                 â”‚
â”‚  5. LoRA ajoute Î” = BÃ—AÃ—entrÃ©e Ã  la sortie originale          â”‚
â”‚                                                                 â”‚
â”‚  6. On peut mettre LoRA partout, c'est un choix                â”‚
â”‚                                                                 â”‚
â”‚  7. Q=Question, K=ClÃ©, V=Valeur pour l'attention               â”‚
â”‚                                                                 â”‚
â”‚  8. Train sur CASIA-WebFace, Test sur LFW/CFP/AgeDB            â”‚
â”‚                                                                 â”‚
â”‚  9. Tu PEUX publier tes poids LoRA sur HuggingFace             â”‚
â”‚                                                                 â”‚
â”‚  10. HuggingFace = plateforme de partage de modÃ¨les ML         â”‚
â”‚                                                                 â”‚
â”‚  11. Pour visualiser: draw.io ou Excalidraw > AI gÃ©nÃ©rative    â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

*Document crÃ©Ã© le 2025-12-22*
